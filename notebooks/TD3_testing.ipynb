{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69cb1fc-5356-445e-a205-077fdd984f50",
   "metadata": {},
   "source": [
    "# Part 2: other environments and RL training\n",
    "---\n",
    "\n",
    "In this notebook we will go over some of the variations of `greenCrabEnv` available in this package, and over the syntax for training RL algorithms on instances of these environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34021e99-0010-4743-8796-48f251a39408",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "---\n",
    "As with Part 1 of this series, uncomment the following cell in order to install our package if you haven't done so already. After that restart the jupyter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99f5d63e-bc09-4eb8-97e7-eb08d52d45cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/rstudio/rl4greencrab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gymnasium in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (0.28.1)\n",
      "Requirement already satisfied: matplotlib in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (3.8.3)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (2.2.1)\n",
      "Requirement already satisfied: pyyaml in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (6.0.1)\n",
      "Requirement already satisfied: scipy in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (1.12.0)\n",
      "Requirement already satisfied: typing in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4greencrab==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4greencrab==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4greencrab==1.0.0) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4greencrab==1.0.0) (0.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/lib/python3.10/site-packages (from pandas->rl4greencrab==1.0.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/venv/lib/python3.10/site-packages (from pandas->rl4greencrab==1.0.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->rl4greencrab==1.0.0) (1.16.0)\n",
      "Building wheels for collected packages: rl4greencrab\n",
      "  Building editable for rl4greencrab (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rl4greencrab: filename=rl4greencrab-1.0.0-py2.py3-none-any.whl size=1067 sha256=a8b1e2f585a58a3eb81cb889e2b33bc31b60bf519ff32c90d914324158f7408e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-eh74nj24/wheels/e9/7e/e6/00c4b11a2574abd59d64425d537139e25fadbde37f002c4dba\n",
      "Successfully built rl4greencrab\n",
      "Installing collected packages: rl4greencrab\n",
      "  Attempting uninstall: rl4greencrab\n",
      "    Found existing installation: rl4greencrab 1.0.0\n",
      "    Uninstalling rl4greencrab-1.0.0:\n",
      "      Successfully uninstalled rl4greencrab-1.0.0\n",
      "Successfully installed rl4greencrab-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b782d73-40ad-4de9-b1ab-f3c52461b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_density, geom_line, geom_point, geom_violin, facet_grid, labs, theme, facet_wrap\n",
    "import stable_baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83ecef-a327-4ba5-9886-e4df5b87a5b4",
   "metadata": {},
   "source": [
    "## 1. Other envs\n",
    "---\n",
    "\n",
    "We will go over two other envs provided by our package: `greenCrabSimplifiedEnv` and `timeSeriesEnv`.\n",
    "Let's focus on the first one of these envs.\n",
    "\n",
    "### greenCrabSimplifiedEnv\n",
    "\n",
    "`greenCrabSimplifiedEnv` is closely related to `greenCrabEnv` and only varies in small aspects.\n",
    "Let's examine these aspecs one by one.\n",
    "The first aspect is its action space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c05ebeea-5c6c-4be6-a45f-4461f7ebcfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (1,), float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl4greencrab import greenCrabSimplifiedEnv\n",
    "gcse = greenCrabSimplifiedEnv()\n",
    "gcse.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248dfd31-ac90-4256-bfc9-8df2cb54ad1a",
   "metadata": {},
   "source": [
    "Actions in this `greenCrabSimplifiedEnv` are between -1 and +1 (in contrast to `greenCrabEnv` where they were in [0, 2000]). \n",
    "This difference in action space is purely conceptual: we linearly associate the segment [-1, 1] to the segment [0, 2000] so that, e.g., an action of -1 corresponds to 0 traps laid, an action of 0 corresponds to 1000 traps laid, and an action of +1 corresponds to 2000 traps laid.\n",
    "Mathematically, this transformation is:\n",
    "$$a = A / 1000 - 1$$,\n",
    "where $A\\in[0,2000]$ and $a\\in[-1,1]$.\n",
    "This transformation of action space is performed because of purely computational reasons related to hyperparameter tuning of RL algorithms.\n",
    "\n",
    "A second difference of `greenCrabSimplifiedEnv` with respect to `greenCrabEnv` is in its observation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41a623c2-25fe-4d23-a152-b6af91a49877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (3,), float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcse.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "013af299-2b80-4066-bf64-507e4f89c04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1., -1., -1.], dtype=float32), {})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcse.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cbc8a-e37d-4fd1-a496-72771915c21a",
   "metadata": {},
   "source": [
    "Here, observations are vectors with *three* components instead of nine, and they are [-1, 1] valued.\n",
    "E.g., consider the following observation after a second time-step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b076834b-12e7-4bec-9233-1ee40a6975cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. , -1. , -0.1], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcse.step(np.float32([-0.1]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e153c9-ed93-435a-98ec-d06ea0724e5f",
   "metadata": {},
   "source": [
    "These three numbers correspond to: 1. the catch per 100 traps in the first five months of the year, 2. the catch per 100 traps in the later four months of the year, 3. the number of traps.\n",
    "These three numbers are transformed to [-1, 1] in a similar fashion to eq. (1).\n",
    "\n",
    "This simplifies the observations, making it easier for RL algorithms to exploit the information they provide.\n",
    "Because of this, we will train our algorithms on `greenCrabSimplifiedEnv` rather than `greenCrabEnv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d37c1e-b344-4058-820a-c59cbee7fa8e",
   "metadata": {},
   "source": [
    "### timeSeriesEnv\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098d67f-f9c1-460d-b505-91ccb8df444d",
   "metadata": {},
   "source": [
    "## 2. Training and evaluating RL algos\n",
    "---\n",
    "\n",
    "Here we cover some basic syntax for training RL algorithms on our envs.\n",
    "We use short train times for the sake of brevity in this example.\n",
    "Typical run-times might need upwards of 1 million time-steps, or possibly up to 10 million time-steps to converge.\n",
    "This number will, however, depend on the particular algorithm used.\n",
    "\n",
    "**Note:** This package also provides a more ergonomic syntax for training through the `train.py` script. \n",
    "To train models this way, run the following command on the terminal:\n",
    "\n",
    "`python scripts/train.py -f hyperpars/ppo-gcse.yml`\n",
    "\n",
    "There, we encode the input to the training algorithm as a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7254fbbd-dd2b-4598-afb1-c13c7ccbae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, TD3\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "gcse = greenCrabSimplifiedEnv() # use of simplify environment how it will affect the model?\n",
    "vec_env = make_vec_env(greenCrabSimplifiedEnv, n_envs=12) # vectorize the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1683f6-f8c0-4742-9343-bcbada85c9d1",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7d2998a-b6a4-46c5-81c6-0bdfbd9f8aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4101cd55294f08ac40d09d55d3e4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", vec_env, verbose=0, \n",
    "    n_steps=2048,\n",
    "    batch_size=128,\n",
    "    n_epochs=8,\n",
    "    gamma=0.999,\n",
    "    gae_lambda=0.98,\n",
    "    ent_coef=0.01,\n",
    "    tensorboard_log=\"/home/rstudio/logs\")\n",
    "\n",
    "model.learn(\n",
    "\ttotal_timesteps=1000_000, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "model.save(\"ppo_gcse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dafd076-e6ca-425a-8e80-e92a572a66c9",
   "metadata": {},
   "source": [
    "### TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ea4b4ce-89d9-4bfd-af99-615adec6f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d6b0010b9f4f0dbe6717f6430cc86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Add some action noise for exploration\n",
    "n_actions = gcse.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = TD3(\"MlpPolicy\", \n",
    "            gcse,\n",
    "            batch_size = 128,\n",
    "            action_noise=action_noise,\n",
    "            gamma = 0.999,\n",
    "            policy_delay = 5,\n",
    "            verbose=0, \n",
    "            tensorboard_log=\"/home/rstudio/logs\") # should I add noise to the model in training\n",
    "model.learn(\n",
    "\ttotal_timesteps=1000_000, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "model.save(\"td3_gcse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a535f2-9d6d-435d-9208-18270e97e6c4",
   "metadata": {},
   "source": [
    "### TQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "045e56c5-430c-4636-8ead-d18b76734d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfa5071d23b4e0ca91be0b73e48bed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TQC(\"MlpPolicy\", vec_env, verbose=0, tensorboard_log=\"/home/rstudio/logs\")\n",
    "model.learn(\n",
    "\ttotal_timesteps=50_000, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "model.save(\"tqc_gcse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e718653-7eb6-4143-9bf1-c027e157c777",
   "metadata": {},
   "source": [
    "## 3. Loading and evaluating RL algos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c05df193-0c95-4cba-a983-b283a11c40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppoAgent = PPO.load(\"ppo_gcse\")\n",
    "td3Agent = TD3.load(\"td3_gcse\")\n",
    "tqcAgent = TQC.load(\"tqc_gcse\")\n",
    "evalEnv = greenCrabSimplifiedEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69193b84-77f7-4a30-90f8-9dc8e7bc0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1fe7bb-c13f-49f6-b6aa-7384c3cc6523",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "929ef021-264c-40d0-bcbb-ea4ddd5d8665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO reward = -0.01739 +/- 0.00006\n"
     ]
    }
   ],
   "source": [
    "mean_rew, std_rew = evaluate_policy(ppoAgent, evalEnv)\n",
    "print(f\"PPO reward = {mean_rew:.5f} +/- {std_rew:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fd846-3b10-47a4-8b66-a1a8f1e94386",
   "metadata": {},
   "source": [
    "### TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e70e461-28ff-4eb2-aa3e-56cb2b1d2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD3 reward = -0.01740 +/- 0.00005\n"
     ]
    }
   ],
   "source": [
    "mean_rew, std_rew = evaluate_policy(td3Agent, evalEnv)\n",
    "print(f\"TD3 reward = {mean_rew:.5f} +/- {std_rew:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2888869e-f44a-4853-8ee5-0ddd41e319b9",
   "metadata": {},
   "source": [
    "### TQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e28caca-5d00-416f-86e6-b029a48bfe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TQC reward = -0.02030 +/- 0.00010\n"
     ]
    }
   ],
   "source": [
    "mean_rew, std_rew = evaluate_policy(tqcAgent, evalEnv)\n",
    "print(f\"TQC reward = {mean_rew:.5f} +/- {std_rew:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
