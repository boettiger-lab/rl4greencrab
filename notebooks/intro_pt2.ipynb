{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69cb1fc-5356-445e-a205-077fdd984f50",
   "metadata": {},
   "source": [
    "# Part 2: other environments and RL training\n",
    "---\n",
    "\n",
    "In this notebook we will go over some of the variations of `greenCrabEnv` available in this package, and over the syntax for training RL algorithms on instances of these environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34021e99-0010-4743-8796-48f251a39408",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "---\n",
    "As with Part 1 of this series, uncomment the following cell in order to install our package if you haven't done so already. After that restart the jupyter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f5d63e-bc09-4eb8-97e7-eb08d52d45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b782d73-40ad-4de9-b1ab-f3c52461b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_density, geom_line, geom_point, geom_violin, facet_grid, labs, theme, facet_wrap\n",
    "from stable_baselines3 impor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83ecef-a327-4ba5-9886-e4df5b87a5b4",
   "metadata": {},
   "source": [
    "## 1. Other envs\n",
    "---\n",
    "\n",
    "We will go over two other envs provided by our package: `greenCrabSimplifiedEnv` and `timeSeriesEnv`.\n",
    "Let's focus on the first one of these envs.\n",
    "\n",
    "### greenCrabSimplifiedEnv\n",
    "\n",
    "`greenCrabSimplifiedEnv` is closely related to `greenCrabEnv` and only varies in small aspects.\n",
    "Let's examine these aspecs one by one.\n",
    "The first aspect is its action space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05ebeea-5c6c-4be6-a45f-4461f7ebcfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (1,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl4greencrab import greenCrabSimplifiedEnv\n",
    "gcse = greenCrabSimplifiedEnv()\n",
    "gcse.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248dfd31-ac90-4256-bfc9-8df2cb54ad1a",
   "metadata": {},
   "source": [
    "Actions in this `greenCrabSimplifiedEnv` are between -1 and +1 (in contrast to `greenCrabEnv` where they were in [0, 2000]). \n",
    "This difference in action space is purely conceptual: we linearly associate the segment [-1, 1] to the segment [0, 2000] so that, e.g., an action of -1 corresponds to 0 traps laid, an action of 0 corresponds to 1000 traps laid, and an action of +1 corresponds to 2000 traps laid.\n",
    "Mathematically, this transformation is:\n",
    "$$a = A / 1000 - 1$$,\n",
    "where $A\\in[0,2000]$ and $a\\in[-1,1]$.\n",
    "This transformation of action space is performed because of purely computational reasons related to hyperparameter tuning of RL algorithms.\n",
    "\n",
    "A second difference of `greenCrabSimplifiedEnv` with respect to `greenCrabEnv` is in its observation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a623c2-25fe-4d23-a152-b6af91a49877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (3,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcse.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "013af299-2b80-4066-bf64-507e4f89c04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1., -1., -1.], dtype=float32), {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcse.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cbc8a-e37d-4fd1-a496-72771915c21a",
   "metadata": {},
   "source": [
    "Here, observations are vectors with *three* components instead of nine, and they are [-1, 1] valued.\n",
    "E.g., consider the following observation after a second time-step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b076834b-12e7-4bec-9233-1ee40a6975cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9775778 , -0.99186665, -0.1       ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcse.step(np.float32([-0.1]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e153c9-ed93-435a-98ec-d06ea0724e5f",
   "metadata": {},
   "source": [
    "These three numbers correspond to: 1. the catch per 100 traps in the first five months of the year, 2. the catch per 100 traps in the later four months of the year, 3. the number of traps.\n",
    "These three numbers are transformed to [-1, 1] in a similar fashion to eq. (1).\n",
    "\n",
    "This simplifies the observations, making it easier for RL algorithms to exploit the information they provide.\n",
    "Because of this, we will train our algorithms on `greenCrabSimplifiedEnv` rather than `greenCrabEnv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d37c1e-b344-4058-820a-c59cbee7fa8e",
   "metadata": {},
   "source": [
    "### timeSeriesEnv\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098d67f-f9c1-460d-b505-91ccb8df444d",
   "metadata": {},
   "source": [
    "## 2. Training and evaluating RL algos\n",
    "---\n",
    "\n",
    "Here we cover some basic syntax for training RL algorithms on our envs.\n",
    "We use short train times for the sake of brevity in this example.\n",
    "Typical run-times might need upwards of 1 million time-steps, or possibly up to 10 million time-steps to converge.\n",
    "This number will, however, depend on the particular algorithm used.\n",
    "\n",
    "**Note:** This package also provides a more ergonomic syntax for training through the `train.py` script. \n",
    "To train models this way, run the following command on the terminal:\n",
    "\n",
    "`python scripts/train.py -f hyperpars/ppo-greencrab-v0-1.yml`\n",
    "\n",
    "There, we encode the input to the training algorithm as a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7254fbbd-dd2b-4598-afb1-c13c7ccbae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, TD3\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "gcse = greenCrabSimplifiedEnv()\n",
    "vec_env = make_vec_env(greenCrabSimplifiedEnv, n_envs=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1683f6-f8c0-4742-9343-bcbada85c9d1",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d2998a-b6a4-46c5-81c6-0bdfbd9f8aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a71821d8cf442d8a0a730de144c35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", vec_env, verbose=0, tensorboard_log=\"/home/rstudio/logs\")\n",
    "model.learn(\n",
    "\ttotal_timesteps=50_000, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "model.save(\"ppo_gcse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dafd076-e6ca-425a-8e80-e92a572a66c9",
   "metadata": {},
   "source": [
    "### TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea4b4ce-89d9-4bfd-af99-615adec6f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02992bd991884d9ca8255e4df54497ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TD3(\"MlpPolicy\", gcse, verbose=0, tensorboard_log=\"/home/rstudio/logs\")\n",
    "model.learn(\n",
    "\ttotal_timesteps=50_000, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "model.save(\"td3_gcse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a535f2-9d6d-435d-9208-18270e97e6c4",
   "metadata": {},
   "source": [
    "### TQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "045e56c5-430c-4636-8ead-d18b76734d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4515d558814f55b67f35d2172b3d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TQC(\"MlpPolicy\", vec_env, verbose=0, tensorboard_log=\"/home/rstudio/logs\")\n",
    "model.learn(\n",
    "\ttotal_timesteps=50_000, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "model.save(\"tqc_gcse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e718653-7eb6-4143-9bf1-c027e157c777",
   "metadata": {},
   "source": [
    "## 3. Loading and evaluating RL algos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c05df193-0c95-4cba-a983-b283a11c40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppoAgent = PPO.load(\"ppo_gcse\")\n",
    "td3Agent = TD3.load(\"td3_gcse\")\n",
    "tqcAgent = TQC.load(\"tqc_gcse\")\n",
    "evalEnv = greenCrabSimplifiedEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69193b84-77f7-4a30-90f8-9dc8e7bc0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1fe7bb-c13f-49f6-b6aa-7384c3cc6523",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "929ef021-264c-40d0-bcbb-ea4ddd5d8665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO reward = -0.020 +/- 0.000090\n"
     ]
    }
   ],
   "source": [
    "mean_rew, std_rew = evaluate_policy(ppoAgent, evalEnv)\n",
    "print(f\"PPO reward = {mean_rew:.3f} +/- {std_rew:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fd846-3b10-47a4-8b66-a1a8f1e94386",
   "metadata": {},
   "source": [
    "### TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e70e461-28ff-4eb2-aa3e-56cb2b1d2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD3 reward = -0.017 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "mean_rew, std_rew = evaluate_policy(td3Agent, evalEnv)\n",
    "print(f\"TD3 reward = {mean_rew:.3f} +/- {std_rew:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2888869e-f44a-4853-8ee5-0ddd41e319b9",
   "metadata": {},
   "source": [
    "### TQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e28caca-5d00-416f-86e6-b029a48bfe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TQC reward = -0.020 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "mean_rew, std_rew = evaluate_policy(tqcAgent, evalEnv)\n",
    "print(f\"TQC reward = {mean_rew:.3f} +/- {std_rew:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194f6ea-687d-48f9-a4c6-2561f7df521c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
