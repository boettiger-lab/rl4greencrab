algo: 'RecurrentPPO'
policy: "MultiInputLstmPolicy"
env_id: "monthenvnorm"
n_envs: 12
tensorboard: "/home/rstudio/logs"
total_timesteps: 15000000
config: 
    "w_mort_scale" : 600
    "growth_k": 0.70
    'random_start': True
    "curriculum": False
    'var_penalty_const': 0.3
model_config:
    'verbose': 0
    'normalize_advantage': True
    'batch_size': 256,
    'n_steps': 1024,
    'gamma': 0.9999,
    'learning_rate': 0.0003,
    'ent_coef': 0.00429,
    'clip_range': 0.1,
    'n_epochs': 10,
    'gae_lambda': 0.9,
    'max_grad_norm': 0.5,
    'vf_coef': 0.19,
    'use_sde': False
    'sde_sample_freq': 8
    'tensorboard_log': "/home/rstudio/logs"
    'policy_kwargs': dict(log_std_init=0.0, 
                          ortho_init=False,
                       lstm_hidden_size=256,
                       n_lstm_layers = 1,
                       enable_critic_lstm=True,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256]))
id: "1"
repo: "cboettig/rl4geco"
save_path: "/home/rstudio/rl4greencrab/saved_agents"
progress_bar: True
