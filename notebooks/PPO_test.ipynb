{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6948a7c5-97d2-4895-9d60-b98493d945da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/rstudio/rl4greencrab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gymnasium in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (0.29.1)\n",
      "Requirement already satisfied: matplotlib in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (3.9.0)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (2.2.2)\n",
      "Requirement already satisfied: pyyaml in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (6.0.1)\n",
      "Requirement already satisfied: scipy in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (1.13.1)\n",
      "Requirement already satisfied: typing in /opt/venv/lib/python3.10/site-packages (from rl4greencrab==1.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4greencrab==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4greencrab==1.0.0) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4greencrab==1.0.0) (0.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4greencrab==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/lib/python3.10/site-packages (from pandas->rl4greencrab==1.0.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/venv/lib/python3.10/site-packages (from pandas->rl4greencrab==1.0.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->rl4greencrab==1.0.0) (1.16.0)\n",
      "Building wheels for collected packages: rl4greencrab\n",
      "  Building editable for rl4greencrab (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rl4greencrab: filename=rl4greencrab-1.0.0-py2.py3-none-any.whl size=1073 sha256=b125839fccc41947614acd0fb477a4cd383c45dfc4c4d3f62424b7ba0fe2f36b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jz0gv_n_/wheels/e9/7e/e6/00c4b11a2574abd59d64425d537139e25fadbde37f002c4dba\n",
      "Successfully built rl4greencrab\n",
      "Installing collected packages: rl4greencrab\n",
      "  Attempting uninstall: rl4greencrab\n",
      "    Found existing installation: rl4greencrab 1.0.0\n",
      "    Uninstalling rl4greencrab-1.0.0:\n",
      "      Successfully uninstalled rl4greencrab-1.0.0\n",
      "Successfully installed rl4greencrab-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5151d7-628b-4e1f-b767-9dfff51a6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /opt/venv/lib/python3.10/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/venv/lib/python3.10/site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/venv/lib/python3.10/site-packages (from gym) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /opt/venv/lib/python3.10/site-packages (from gym) (0.0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in /opt/venv/lib/python3.10/site-packages (3.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/venv/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /opt/venv/lib/python3.10/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.10/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from optuna) (24.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/venv/lib/python3.10/site-packages (from optuna) (2.0.30)\n",
      "Requirement already satisfied: tqdm in /opt/venv/lib/python3.10/site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in /opt/venv/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/venv/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rl_zoo3 in /opt/venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: sb3-contrib<3.0,>=2.3.0 in /opt/venv/lib/python3.10/site-packages (from rl_zoo3) (2.3.0)\n",
      "Collecting gymnasium~=0.29.1 (from rl_zoo3)\n",
      "  Using cached gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-sb3<4.0,>=3.0 in /opt/venv/lib/python3.10/site-packages (from rl_zoo3) (3.0)\n",
      "Requirement already satisfied: tqdm in /opt/venv/lib/python3.10/site-packages (from rl_zoo3) (4.66.4)\n",
      "Requirement already satisfied: rich in /opt/venv/lib/python3.10/site-packages (from rl_zoo3) (13.7.1)\n",
      "Requirement already satisfied: optuna>=3.0 in /opt/venv/lib/python3.10/site-packages (from rl_zoo3) (3.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/venv/lib/python3.10/site-packages (from rl_zoo3) (6.0.1)\n",
      "Requirement already satisfied: pytablewriter~=1.2 in /opt/venv/lib/python3.10/site-packages (from rl_zoo3) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium~=0.29.1->rl_zoo3) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium~=0.29.1->rl_zoo3) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium~=0.29.1->rl_zoo3) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/venv/lib/python3.10/site-packages (from gymnasium~=0.29.1->rl_zoo3) (0.0.4)\n",
      "Requirement already satisfied: huggingface-hub~=0.8 in /opt/venv/lib/python3.10/site-packages (from huggingface-sb3<4.0,>=3.0->rl_zoo3) (0.23.1)\n",
      "Requirement already satisfied: wasabi in /opt/venv/lib/python3.10/site-packages (from huggingface-sb3<4.0,>=3.0->rl_zoo3) (1.1.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/venv/lib/python3.10/site-packages (from optuna>=3.0->rl_zoo3) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /opt/venv/lib/python3.10/site-packages (from optuna>=3.0->rl_zoo3) (6.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from optuna>=3.0->rl_zoo3) (24.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/venv/lib/python3.10/site-packages (from optuna>=3.0->rl_zoo3) (2.0.30)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /opt/venv/lib/python3.10/site-packages (from pytablewriter~=1.2->rl_zoo3) (59.6.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /opt/venv/lib/python3.10/site-packages (from pytablewriter~=1.2->rl_zoo3) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /opt/venv/lib/python3.10/site-packages (from pytablewriter~=1.2->rl_zoo3) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /opt/venv/lib/python3.10/site-packages (from pytablewriter~=1.2->rl_zoo3) (3.2.0)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /opt/venv/lib/python3.10/site-packages (from pytablewriter~=1.2->rl_zoo3) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /opt/venv/lib/python3.10/site-packages (from pytablewriter~=1.2->rl_zoo3) (0.1.6)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /opt/venv/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3) (1.3.2)\n",
      "Requirement already satisfied: stable-baselines3<3.0,>=2.3.0 in /opt/venv/lib/python3.10/site-packages (from sb3-contrib<3.0,>=2.3.0->rl_zoo3) (2.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/venv/lib/python3.10/site-packages (from rich->rl_zoo3) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/venv/lib/python3.10/site-packages (from rich->rl_zoo3) (2.18.0)\n",
      "Requirement already satisfied: Mako in /opt/venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=3.0->rl_zoo3) (1.3.3)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/venv/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2024.5.0)\n",
      "Requirement already satisfied: requests in /opt/venv/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2.31.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3) (0.1.2)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /opt/venv/lib/python3.10/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=1.2->rl_zoo3) (5.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/venv/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna>=3.0->rl_zoo3) (3.0.3)\n",
      "Requirement already satisfied: torch>=1.13 in /opt/venv/lib/python3.10/site-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (2.3.0)\n",
      "Requirement already satisfied: pandas in /opt/venv/lib/python3.10/site-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/venv/lib/python3.10/site-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (3.9.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /opt/venv/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /opt/venv/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3) (1.16.0)\n",
      "Requirement already satisfied: sympy in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/venv/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna>=3.0->rl_zoo3) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (3.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/venv/lib/python3.10/site-packages (from pandas->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/venv/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/venv/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/venv/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/venv/lib/python3.10/site-packages (from sympy->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib<3.0,>=2.3.0->rl_zoo3) (1.3.0)\n",
      "Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "Installing collected packages: gymnasium\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 1.0.0a2\n",
      "    Uninstalling gymnasium-1.0.0a2:\n",
      "      Successfully uninstalled gymnasium-1.0.0a2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "shimmy 2.0.0 requires gymnasium>=1.0.0a1, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gymnasium-0.29.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym\n",
    "%pip install optuna\n",
    "%pip install rl_zoo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2388b9e2-42b5-4edc-9910-ccb9cc2a1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_density, geom_line, geom_point, geom_violin, facet_grid, labs, theme, facet_wrap\n",
    "\n",
    "from stable_baselines3 import PPO, TD3\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from rl4greencrab import simulator\n",
    "import gym\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from commented_env import greenCrabSimplifiedEnv\n",
    "import gymnasium as gym\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from gymnasium import spaces\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sample_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a7f2d58-19da-4980-b0a2-ec0704cd9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"/home/rstudio/rl4greencrab/notebooks/env_log.txt\",format='%(levelname)s: %(message)s', level=logging.DEBUG)\n",
    "\n",
    "class greenCrabEnv(gym.Env):\n",
    "    \n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config=None,\n",
    "    ):\n",
    "        # if config == {}:\n",
    "        #     config = {\n",
    "        #         \"Tmax\": 100,\n",
    "        #         \"growth_k\": 0.43, \"growth_xinf\": 109, \"growth_sd\": 2.5, \"nmortality\": 0.03,\n",
    "        #         \"trapm_sigma\": 0.15, \"trapm_xmax\": 44, \"trapm_pmax\": 0.0005, \"trapf_pmax\": 0.0008,\n",
    "        #         \"trapf_k\": 0.5, \"trapf_midpoint\": 45, \"init_mean_recruit\": 15, \"init_sd_recruit\": 1.5,\n",
    "        #         \"init_mean_adult\": 65, \"init_sd_adult\": 8, \"init_n_recruit\": 1000, \"init_n_adult\": 1000,\n",
    "        #         \"w_mort_scale\": 5, \"K\": 25000, \"imm\": 10, \"r\": 50, \"area\": 4000,\"loss_a\": 0.265,\n",
    "        #         \"loss_b\": 2.80, \"loss_c\": 2.99, \"minsize\": 5, \"maxsize\": 110, \"nsize\": 21, \"ntime\":9,\"delta_t\": 1/12,\n",
    "        #         \"env_stoch\": 0.1, \"action_reward_scale\":0.001\n",
    "        #     }\n",
    "        \n",
    "        config=config or {}\n",
    "        \n",
    "        # parameters\n",
    "        self.growth_k = np.float32(config.get(\"growth_k\", 0.43))\n",
    "        self.growth_xinf = np.float32(config.get(\"growth_xinf\", 109))\n",
    "        self.growth_sd = np.float32(config.get(\"growth_sd\", 2.5))\n",
    "        self.nmortality = np.float32(config.get(\"nmortality\", 0.03))\n",
    "        \n",
    "        self.trapm_sigma = np.float32(config.get(\"trapm_sigma\", 6))\n",
    "        self.trapm_xmax = np.float32(config.get(\"trapm_xmax\", 47))\n",
    "        self.trapm_pmax = np.float32(config.get(\"trapm_pmax\", 2.26e-6))\n",
    "        #\n",
    "        self.trapf_pmax = np.float32(config.get(\"trapf_pmax\", 8.3e-7))\n",
    "        self.trapf_k = np.float32(config.get(\"trapf_k\", 0.4))\n",
    "        self.trapf_midpoint = np.float32(config.get(\"trapf_midpoint\", 41))\n",
    "        #\n",
    "        self.traps_pmax = np.float32(config.get(\"traps_pmax\", 2.75e-5))\n",
    "        self.traps_k = np.float32(config.get(\"traps_k\", 0.4))\n",
    "        self.traps_midpoint = np.float32(config.get(\"traps_midpoint\", 45))\n",
    "        \n",
    "        self.init_mean_recruit = config.get(\"init_mean_recruit\", 15)\n",
    "        self.init_sd_recruit = config.get(\"init_sd_recruit\", 1.5)\n",
    "        self.init_mean_adult = config.get(\"init_mean_adult\", 65)\n",
    "        self.init_sd_adult = config.get(\"init_sd_adult\", 8)\n",
    "        self.init_n_recruit = config.get(\"init_n_recruit\", 0)\n",
    "        self.init_n_adult = config.get(\"init_n_adult\", 0)\n",
    "        \n",
    "        self.w_mort_scale = config.get(\"w_mort_scale\", 5)\n",
    "        self.K = config.get(\"K\", 25000) #carrying capacity\n",
    "        self.imm = config.get(\"imm\", 1000) #colonization/immigration rate\n",
    "        self.r = config.get(\"r\", 1) #intrinsic rate of growth\n",
    "\n",
    "        self.max_action = config.get(\"max_action\", 2000)\n",
    "        self.max_obs = config.get(\"max_obs\", 2000)\n",
    "        \n",
    "        self.area = config.get(\"area\", 4000)\n",
    "        self.loss_a = config.get(\"loss_a\", 0.265)\n",
    "        self.loss_b = config.get(\"loss_b\", 2.80)\n",
    "        self.loss_c = config.get(\"loss_c\", 2.99)\n",
    "        \n",
    "        self.minsize = config.get(\"minsize\", 5)\n",
    "        self.maxsize = config.get(\"maxsize\", 110)\n",
    "        self.nsize = config.get(\"nsize\", 21)\n",
    "        self.ntime = config.get(\"ntime\", 9)\n",
    "        \n",
    "        self.delta_t = config.get(\"delta_t\", 1/12)\n",
    "        self.env_stoch = config.get(\"env_stoch\", 0.1)\n",
    "        \n",
    "        self.action_reward_scale = np.array(config.get(\"action_reward_scale\", [0.1, 0.1, 10]))\n",
    "        self.action_reward_exponent = config.get(\"action_reward_exponent\", 1)\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "        # Preserve these for reset\n",
    "        self.observations = np.zeros(shape=9, dtype=np.float32)\n",
    "        self.reward = 0\n",
    "        self.years_passed = 0\n",
    "        self.Tmax = config.get(\"Tmax\", 100)\n",
    "                \n",
    "        # Initial variables\n",
    "        self.bndry = self.boundary()\n",
    "        self.state = self.init_state()\n",
    "        self.midpts = self.midpoints()\n",
    "        self.gm_ker = self.g_m_kernel()\n",
    "        self.w_mort = self.w_mortality()\n",
    "        self.w_mort_exp = np.exp(-self.w_mort)\n",
    "        self.pmort = np.exp(-self.nmortality)\n",
    "\n",
    "        # Action space\n",
    "        # action -- # traps per month\n",
    "        self.action_space = spaces.Box(\n",
    "            np.array([0, 0, 0], dtype=np.float32),\n",
    "            np.array(3*[self.max_action], dtype=np.float32),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        \n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            np.zeros(shape=self.ntime, dtype=np.float32),\n",
    "            self.max_obs * np.ones(shape=self.ntime, dtype=np.float32),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Size selective harvest rate, given action\n",
    "        harvest_rate = (\n",
    "            1 - np.exp(-(\n",
    "                self.size_sel_norm() * action[0] +\n",
    "                self.size_sel_log(self.trapf_pmax, self.trapf_midpoint, self.trapf_k) * action[1] +\n",
    "                self.size_sel_log(self.traps_pmax, self.traps_midpoint, self.traps_k) * action[2]\n",
    "            ))\n",
    "        )\n",
    "        \n",
    "        # Add population at t=1\n",
    "        size_freq = np.zeros(shape=(self.nsize, self.ntime), dtype='object')\n",
    "        size_freq[:, 0] = self.state\n",
    "        \n",
    "        # Create array to store # removed\n",
    "        removed = np.zeros(shape=(self.nsize, self.ntime), dtype='object')\n",
    "        \n",
    "        # Calculate removed and record observation at t=1\n",
    "        removed[:, 0] = [np.random.binomial(size_freq[k, 0], harvest_rate[k]) for k in range(self.nsize)]\n",
    "        self.observations[0] = np.sum(removed[:, 0])\n",
    "        \n",
    "        # Loop through intra-annual change (9 total months), t=2+\n",
    "        for j in range(self.ntime - 1):\n",
    "            n_j = self.gm_ker @ (size_freq[:, j] - removed[:, j])\n",
    "            size_freq[:, j+1] = [np.random.binomial(n=n_j[k], p=self.pmort) for k in range(self.nsize)]\n",
    "            removed[:, j+1] = [np.random.binomial(size_freq[k, j+1], harvest_rate[k]) for k in range(self.nsize)]\n",
    "        \n",
    "        # Record the catch in the observation space\n",
    "        self.observations = np.array([np.sum(removed[:, j]) for j in range(self.ntime)], dtype=np.float32)\n",
    "        \n",
    "        # Calculate new adult population after overwinter mortality\n",
    "        new_adults = [np.random.binomial(size_freq[k, 8], self.w_mort_exp[k]) for k in range(self.nsize)]\n",
    "        \n",
    "        # Simulate new recruits\n",
    "        local_recruits = np.random.normal(self.dd_growth(size_freq[:, self.ntime-1]), self.env_stoch)\n",
    "        nonlocal_recruits = np.random.poisson(self.imm) * (1 - np.sum(size_freq[:, self.ntime-1]) / self.K)\n",
    "        recruit_total = local_recruits + nonlocal_recruits\n",
    "        \n",
    "        # Get sizes of recruits\n",
    "        recruit_sizes = (norm.cdf(self.bndry[1:(self.nsize+1)], self.init_mean_recruit, self.init_sd_recruit) -\n",
    "                         norm.cdf(self.bndry[0:self.nsize], self.init_mean_recruit, self.init_sd_recruit)) * recruit_total\n",
    "        \n",
    "        # Store new population size (and cap off at zero pop)\n",
    "        self.state = np.maximum(recruit_sizes + new_adults, 0)\n",
    "        \n",
    "        # Calculate reward\n",
    "        self.reward = self.reward_func(action)\n",
    "        self.years_passed += 1\n",
    "        \n",
    "        done = bool(self.years_passed > self.Tmax)\n",
    "        \n",
    "        return self.observations, self.reward, done, done, {}\n",
    "\n",
    "\n",
    "        \n",
    "    def reset(self, *, seed=42, options=None):\n",
    "        self.state = self.init_state()\n",
    "        self.years_passed = 0\n",
    "\n",
    "        # for tracking only\n",
    "        self.reward = 0\n",
    "\n",
    "        self.observations = np.zeros(shape=self.ntime, dtype=np.float32)\n",
    "\n",
    "        return self.observations, {}\n",
    "\n",
    "    #################\n",
    "    #helper functions\n",
    "\n",
    "    #set up boundary points of IPM mesh\n",
    "    def boundary(self):\n",
    "        boundary = self.minsize+np.arange(0,(self.nsize+1),1)*(self.maxsize-self.minsize)/self.nsize\n",
    "        return boundary\n",
    "\n",
    "    #set up mid points of IPM mesh\n",
    "    def midpoints(self):\n",
    "        midpoints = 0.5*(self.bndry[0:self.nsize]+self.bndry[1:(self.nsize+1)])\n",
    "        return midpoints\n",
    "\n",
    "    #function for initial state\n",
    "    def init_state(self):\n",
    "        init_pop = (norm.cdf(self.bndry[1:(self.nsize+1)],self.init_mean_adult,self.init_sd_adult)-\\\n",
    "         norm.cdf(self.bndry[0:self.nsize],self.init_mean_adult,self.init_sd_adult))*self.init_n_adult+\\\n",
    "        (norm.cdf(self.bndry[1:(self.nsize+1)],self.init_mean_recruit,self.init_sd_recruit)-\\\n",
    "         norm.cdf(self.bndry[0:self.nsize],self.init_mean_recruit,self.init_sd_recruit))*self.init_n_recruit\n",
    "        return init_pop\n",
    "\n",
    "    #function for logistic size selectivity curve\n",
    "    def size_sel_log(self, trap_pmax, trap_midpts, trap_k):\n",
    "        size_sel = trap_pmax/(1+np.exp(-trap_k*(self.midpts-trap_midpts)))\n",
    "        return size_sel\n",
    "\n",
    "    #function for gaussian size selectivity curve\n",
    "    def size_sel_norm(self):\n",
    "        size_sel = self.trapm_pmax*np.exp(-(self.midpts-self.trapm_xmax)**2/(2*self.trapm_sigma**2))\n",
    "        return size_sel\n",
    "\n",
    "    #function for growth/mortality kernel\n",
    "    def g_m_kernel(self):\n",
    "        array = np.empty(shape=(self.nsize,self.nsize),dtype='object')\n",
    "        for i in range(self.nsize):\n",
    "            mean = (self.growth_xinf-self.midpts[i])*(1-np.exp(-self.growth_k*self.delta_t)) + self.midpts[i]\n",
    "            array[:,i] = (norm.cdf(self.bndry[1:(self.nsize+1)],mean,self.growth_sd)-\\\n",
    "                          norm.cdf(self.bndry[0:self.nsize],mean,self.growth_sd))\n",
    "        return array\n",
    "\n",
    "    #function for overwinter mortality\n",
    "    def w_mortality(self):\n",
    "        wmort = self.w_mort_scale/self.midpts\n",
    "        return wmort\n",
    "\n",
    "    #function for density dependent growth\n",
    "    def dd_growth(self,popsize):\n",
    "        dd_recruits = np.sum(popsize)*self.r*(1-np.sum(popsize)/self.K)\n",
    "        return dd_recruits\n",
    "\n",
    "    #function for reward\n",
    "    # two part reward function:\n",
    "    # 1. impact on environment (function of crab density)\n",
    "    # 2. penalty for how much effort we expended (function of action)\n",
    "    def reward_func(self,action):\n",
    "        def trap_cost(action, max_action, exponent):\n",
    "            return np.array(\n",
    "                [\n",
    "                    (action[0]/max_action) ** exponent,\n",
    "                    (action[1]/max_action) ** exponent,\n",
    "                    (action[2]/max_action) ** exponent,\n",
    "                ]\n",
    "            )\n",
    "        reward = (\n",
    "            -self.loss_a \n",
    "            /\n",
    "            (\n",
    "                1+np.exp(-self.loss_b*(np.sum(self.state)/self.area-self.loss_c))\n",
    "            )\n",
    "            - np.sum(\n",
    "                self.action_reward_scale \n",
    "                * trap_cost(action, self.max_action, self.action_reward_exponent) \n",
    "            )\n",
    "        )\n",
    "        return reward\n",
    "\n",
    "\n",
    "class greenCrabSimplifiedEnv(greenCrabEnv):\n",
    "    \"\"\" like invasive_IPM but with simplified observations and normalized to -1, 1 space. \"\"\"\n",
    "    def __init__(self, config={}):\n",
    "        super().__init__(config=config)\n",
    "        self.observation_space = spaces.Box(\n",
    "            np.array([-1,-1], dtype=np.float32),\n",
    "            np.array([1,1], dtype=np.float32),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.action_space = spaces.Box(\n",
    "            np.float32([-1, -1, -1]),\n",
    "            np.float32([1, 1, 1]),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.max_action = config.get('max_action', 2000) # ad hoc based on previous values\n",
    "        self.cpue_normalization = config.get('cpue_normalization', 100)\n",
    "        \n",
    "    def step(self, action):\n",
    "        action_natural_units = np.maximum( self.max_action * (1 + action)/2 , 0.)\n",
    "        obs, rew, term, trunc, info = super().step(\n",
    "            np.float32(action_natural_units)\n",
    "        )\n",
    "        normalized_cpue = 2 * self.cpue_2(obs, action_natural_units) - 1\n",
    "        # observation = np.float32(np.append(normalized_cpue, action))\n",
    "        observation = normalized_cpue\n",
    "        rew = 10 * rew # use larger rewards, possibly makes trainer easier?\n",
    "        return observation, rew, term, trunc, info\n",
    "\n",
    "    def reset(self, *, seed=42, options=None):\n",
    "        _, info = super().reset(seed=seed, options=options)\n",
    "\n",
    "        # completely new  obs\n",
    "        return - np.ones(shape=self.observation_space.shape, dtype=np.float32), info\n",
    "\n",
    "    def cpue_2(self, obs, action_natural_units):\n",
    "        if any(action_natural_units <= 0):\n",
    "            return np.float32([0,0])\n",
    "        cpue_2 = np.float32([\n",
    "            np.sum(obs[0:5]) / (self.cpue_normalization * action_natural_units[0]),\n",
    "            np.sum(obs[5:]) / (self.cpue_normalization * action_natural_units[0])\n",
    "        ])\n",
    "        return cpue_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3aca9d7a-ff9f-472c-8eb4-0cde1026cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse = greenCrabSimplifiedEnv()\n",
    "vec_env = make_vec_env(greenCrabSimplifiedEnv, n_envs=12)\n",
    "eval_envs = vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4d54cb5-c8cc-4336-b373-0890be552e2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LiveError",
     "evalue": "Only one live display may be active at once",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLiveError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, vec_env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m      2\u001b[0m             batch_size \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m64\u001b[39m, \u001b[38;5;66;03m# no\u001b[39;00m\n\u001b[1;32m      3\u001b[0m             n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, \u001b[38;5;66;03m# no\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m             vf_coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9694540149524578\u001b[39m, \u001b[38;5;66;03m# no\u001b[39;00m\n\u001b[1;32m     12\u001b[0m             tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/rstudio/logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# model.save(\"ppo_gcse\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:295\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    285\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    287\u001b[0m total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_learn(\n\u001b[1;32m    288\u001b[0m     total_timesteps,\n\u001b[1;32m    289\u001b[0m     callback,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m     progress_bar,\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 295\u001b[0m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:84\u001b[0m, in \u001b[0;36mBaseCallback.on_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Update num_timesteps in case training was done before\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:209\u001b[0m, in \u001b[0;36mCallbackList._on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_training_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 209\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:84\u001b[0m, in \u001b[0;36mBaseCallback.on_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Update num_timesteps in case training was done before\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:699\u001b[0m, in \u001b[0;36mProgressBarCallback._on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_training_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# Initialize progress bar\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Remove timesteps that were done in previous training sessions\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_timesteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_timesteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/tqdm/rich.py:113\u001b[0m, in \u001b[0;36mtqdm_rich.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m options\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleave)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prog \u001b[38;5;241m=\u001b[39m Progress(\u001b[38;5;241m*\u001b[39mprogress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prog\u001b[38;5;241m.\u001b[39madd_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/progress.py:1168\u001b[0m, in \u001b[0;36mProgress.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgress\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1168\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/progress.py:1159\u001b[0m, in \u001b[0;36mProgress.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the progress display.\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/live.py:113\u001b[0m, in \u001b[0;36mLive.start\u001b[0;34m(self, refresh)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_live\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_screen:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/console.py:836\u001b[0m, in \u001b[0;36mConsole.set_live\u001b[0;34m(self, live)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mLiveError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one live display may be active at once\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;241m=\u001b[39m live\n",
      "\u001b[0;31mLiveError\u001b[0m: Only one live display may be active at once"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", vec_env, verbose=0, \n",
    "            batch_size =  64, # no\n",
    "            n_steps = 32, # no\n",
    "            gamma = 0.95, # no\n",
    "            learning_rate =  0.9, # orginal = 0.9447561168646137\n",
    "            ent_coef = 7.676877009214456e-07, # no\n",
    "            clip_range =  0.1, # no\n",
    "            n_epochs = 20, \n",
    "            gae_lambda = 0.9, # no\n",
    "            max_grad_norm = 5, # no\n",
    "            vf_coef = 0.9694540149524578, # no\n",
    "            tensorboard_log=\"/home/rstudio/logs\")\n",
    "model.learn(\n",
    "\ttotal_timesteps=5, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "# model.save(\"ppo_gcse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc0a0ff-63b8-40c4-b589-01f76104dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {'gamma': 0.9999, \n",
    "                  'learning_rate': 0.020439420278073966, \n",
    "                  'batch_size': 16, 'buffer_size': 10000, \n",
    "                  'learning_starts': 0, \n",
    "                  'train_freq': 16, \n",
    "                  'tau': 0.05, \n",
    "                  'log_std_init': -2.392885376919297, \n",
    "                  'net_arch': 'big', \n",
    "                  'n_quantiles': 31, \n",
    "                  'top_quantiles_to_drop_per_net': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76d56702-568c-443b-9375-4b8d6299fedf",
   "metadata": {},
   "outputs": [
    {
     "ename": "LiveError",
     "evalue": "Only one live display may be active at once",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLiveError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m TQC(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m             vec_env, \n\u001b[1;32m      3\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m             tau \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m, \n\u001b[1;32m     11\u001b[0m             top_quantiles_to_drop_per_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/sb3_contrib/tqc/tqc.py:302\u001b[0m, in \u001b[0;36mTQC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTQC,\n\u001b[1;32m    295\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    301\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTQC:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:322\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[1;32m    307\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOffPolicyAlgorithm:\n\u001b[1;32m    314\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_learn(\n\u001b[1;32m    315\u001b[0m         total_timesteps,\n\u001b[1;32m    316\u001b[0m         callback,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         progress_bar,\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must set the environment before calling learn()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:84\u001b[0m, in \u001b[0;36mBaseCallback.on_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Update num_timesteps in case training was done before\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:209\u001b[0m, in \u001b[0;36mCallbackList._on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_training_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 209\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:84\u001b[0m, in \u001b[0;36mBaseCallback.on_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Update num_timesteps in case training was done before\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_training_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:699\u001b[0m, in \u001b[0;36mProgressBarCallback._on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_training_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# Initialize progress bar\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Remove timesteps that were done in previous training sessions\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_timesteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_timesteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/tqdm/rich.py:113\u001b[0m, in \u001b[0;36mtqdm_rich.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m options\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleave)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prog \u001b[38;5;241m=\u001b[39m Progress(\u001b[38;5;241m*\u001b[39mprogress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prog\u001b[38;5;241m.\u001b[39madd_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/progress.py:1168\u001b[0m, in \u001b[0;36mProgress.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgress\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1168\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/progress.py:1159\u001b[0m, in \u001b[0;36mProgress.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the progress display.\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/live.py:113\u001b[0m, in \u001b[0;36mLive.start\u001b[0;34m(self, refresh)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_live\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_screen:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/rich/console.py:836\u001b[0m, in \u001b[0;36mConsole.set_live\u001b[0;34m(self, live)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mLiveError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one live display may be active at once\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;241m=\u001b[39m live\n",
      "\u001b[0;31mLiveError\u001b[0m: Only one live display may be active at once"
     ]
    }
   ],
   "source": [
    "model = TQC(\"MlpPolicy\", \n",
    "            vec_env, \n",
    "            verbose=0, \n",
    "            gamma= 0.9999, \n",
    "            learning_rate = 0.020439420278073966, \n",
    "            batch_size = 16, \n",
    "            buffer_size = 10000, \n",
    "            learning_starts= 0, \n",
    "            train_freq = 16, \n",
    "            tau = 0.05, \n",
    "            top_quantiles_to_drop_per_net = 1)\n",
    "model.learn(\n",
    "\ttotal_timesteps=1000000, \n",
    "\tprogress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d19cba92-7782-43c2-ba05-db531856fcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.126776689500633e-05"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcse.reward_func([0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1953e8f-e498-4a01-8a93-d91f04ae6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1895163-5082-404d-a778-b7b00c4877e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppoAgent = PPO.load(\"ppo_gcse\")\n",
    "tunningAgent = TD3.load(\"tunning_best_gcse\")\n",
    "evalEnv = greenCrabSimplifiedEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75c6fd38-0402-40f9-a68d-0d225b2f67b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00013980890837148188\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00032913614637149923\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0010596732821369717\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.004963474836793878\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.030974938258466016\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.14113779899025197\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2376158711434138\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2592554098044239\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2630517205509694\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26391559677241017\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264230279692708\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643721923266847\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443932446594814\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644773526843134\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445975761889745\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644672181712166\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644709097042431\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445134220277383\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644527570061448\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442431721458276\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644135041590866\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444515071149255\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442880750059145\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644069939986555\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264437026428437\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644267905799519\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439321259428133\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442214905954287\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644590577871759\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644287739977543\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436951642527584\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437957110494065\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264371352678758\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643992264324698\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643831639199076\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643921919649188\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643812154085378\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439250161201244\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441448993782085\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436692399622275\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441724766832964\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644249102208257\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643987848415005\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644237963443409\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644117160705237\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442597286318315\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443630753315933\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643998721126496\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644267940405189\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442546100412584\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441425620565023\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644185947315484\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440536583332847\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440246107837595\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644460594141942\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441177492537166\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643872813150001\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437540038029783\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643844293812211\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643991125854873\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442711448002865\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643628283662465\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644119633881069\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644543144991154\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644535954967349\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26447883319183363\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445434509848065\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644614746987508\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644592200541626\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644417619203614\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644338507244949\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442521464080954\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644204772949633\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643995134124883\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644312704655422\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442350518874796\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440772794036393\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644198546703833\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644115878840007\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644317784735027\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444820943865693\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644328410950374\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644025673927933\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643882762820783\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643590767834946\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439335670169634\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442790958611107\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440615919660926\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643989622257474\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439949735438245\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644112329183006\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264409385512339\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437487866480003\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644200723879229\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644160700867109\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644128155108838\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437173970490285\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438499937472726\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643754048216182\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644051606711518\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443389668464756\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.000143166770644181\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00034577929565577455\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0012950014831940707\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.006982564690580211\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.04346672876388362\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.15918745496370548\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.24164163977562725\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2593981706177901\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26303572803511893\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26395449445278113\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26424314367498813\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436162612983183\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644291613054574\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644084229428688\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644572410890109\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444547306951444\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644366475622686\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644189759834427\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438867355753504\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644080147156189\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644286984179421\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643762182494461\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442070576691373\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644359840940613\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644298938828329\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444461927268437\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441834367135286\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644032882211807\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439260659923763\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441480929034733\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440988844397856\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643920444420464\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440819953322\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440007744885463\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438139945179157\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441961578274886\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644578892739903\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439161937748723\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643979032616559\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264417116420261\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440109046738963\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643855991408967\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644205758097881\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442339437330076\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444681478084947\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264432539426414\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442131485185927\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440641246189256\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440834329404816\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644117178047366\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643999886247952\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440383792745964\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442808649011473\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446257632819237\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2645116460003557\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446849319846655\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644859649823764\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644849302022287\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441284250542446\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443653100300235\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440928907380984\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438059532568575\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442430745201073\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439995345139505\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440452458754204\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440793630100323\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644208176486242\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445342262736754\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443765970733624\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445408972830825\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644252332105144\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644639319073203\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445742134606065\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644393176649194\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444266658671856\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644415252002837\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439682677290527\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644140147026937\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644079538698294\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438607797011865\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644135163062329\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643796156918443\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643960878398475\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442663537148214\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644467044285271\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264412574256771\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440737456803154\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644080622677994\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644057510370138\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644237418260604\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644282953682805\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441024300385024\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445602233936594\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643983421317774\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440420531924125\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643909799086656\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440385690474777\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644049013342191\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643900508565983\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441550031756406\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439070380769164\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0001430710180492525\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00035265514674628586\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0011905463248874208\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.005993590162625867\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0379366900845067\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.15857527127160018\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.24169921346498746\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.25984993470498924\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26320766383563476\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26392140026920075\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26426023724605247\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644038199139395\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644263355747361\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644236633186621\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264399296599303\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443242279668344\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644202005742235\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441494778738656\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644010275682933\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439708570635106\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644024246354075\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441704702054103\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644267973943854\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643886097042885\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439803264968714\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643787644124486\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441796032031695\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439482672446374\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442337119454673\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440723721166715\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643917731577118\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440237759537666\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437494484905555\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644072130061399\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441444358297217\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446724614411726\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644546858800662\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644466820172929\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643942687684233\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643759036924267\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440824480361236\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643894188773388\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440692424779716\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441465968442934\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439742471753236\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643776938989786\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643879576241139\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644198554523486\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644187210489788\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643932664558624\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439620031319494\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442633966344214\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643782804719479\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438542844262053\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438945649987966\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440973859148725\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264444913038368\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644506914359078\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644408231041543\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644098585757237\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644141785417794\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644118453072637\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644442145746492\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444277975969055\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264424945041396\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439856559503866\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445441608041026\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644477496054142\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644249853330866\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445690536612276\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264446112782339\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442266261599773\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443949108170944\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441748583009206\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644223622190339\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437446786090785\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26433297100095204\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643627589256524\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437341749304993\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439047353590694\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444556866606633\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444279206188587\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644063429323672\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643933143635124\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438010024622377\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644036505982903\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644081353307497\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440005304932196\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441372478531394\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438335667849566\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264418837608192\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440515618424054\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644184440928943\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443151958815003\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439379677713465\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441805813698743\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644424171052048\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444852173067934\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442417563292686\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440400474768516\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644181123956116\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0001419576925244581\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0003385874085813732\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.001161535673232829\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.006483219868901659\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.04036686690996456\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.15900987237989866\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2444174977092143\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2598288204921042\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2632693415071125\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2640225751660669\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26423846182293337\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438519595559345\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444763556090095\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644158131781787\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644244835016038\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644255351988579\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443363503519557\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644182216102259\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440706661552466\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644227632053934\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439265820958097\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643872567663044\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438545871040764\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643805363231097\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440656314195937\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438263994968003\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441131979190186\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644139091738868\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440004600822503\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442923771016064\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644348523096209\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644309086600213\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439839411180577\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644370113496872\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441436966464765\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644011604713499\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644180710580062\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644016150785391\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644228049172477\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643904542882403\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644070346144857\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644514961378224\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644758124361926\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445222117526823\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441210210751365\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644249833876701\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438693568478316\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440207708085006\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643975443731499\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643931747977597\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441846707400524\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644392295201241\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644332293798584\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644528477472327\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644266329836125\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644567052649407\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442983552286536\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644335592736916\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440318983071837\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264379686832163\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438573398367254\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643576672219434\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436628798307715\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438753744017285\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643882085202639\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643969868181573\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441717213223526\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442588037341663\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444293956896825\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26447100914460864\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443094900405506\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644237118060674\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644026561293745\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439637420378403\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437667725054675\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441383645244515\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439618522731106\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643804069847354\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644119990234976\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643937452768985\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644237115984934\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643769486416767\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643851599820524\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644070958420186\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644208656631072\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437856233421136\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644156829983881\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443260168667493\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438928215528873\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438900371317176\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643793981426563\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644003956533713\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264382006870325\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440059825971346\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444008379526013\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644505543660357\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442976663988826\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644378507761395\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441301091092895\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644324178390027\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643742783948313\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00014144153758005875\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00032010126357131656\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0010688990578873472\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.005229354939822863\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0335103541069463\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.14221004492046999\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2362873331956061\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2587132026177846\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26278873040347406\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2639758135448499\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2642363560484216\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436227790007494\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644077109364758\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644315569899787\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441132745313245\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644533325508783\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644195732953696\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644244453555172\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443013569476287\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644430981312903\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644235767886761\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443490848313855\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644555526141666\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264461432037839\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644205298105669\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643923121489532\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644390863992987\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644524925057899\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644133510202489\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440768596827546\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436669715507183\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643880262167044\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440824587498113\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443462677425095\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644194033012983\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644384633192183\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644506569398648\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644051137661481\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644289270073152\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444897719808735\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26447383073440073\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445070597385933\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644161547710945\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442448168726285\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644211458568289\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644544458772938\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644284508343967\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644361423901518\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444546913790884\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444922831558476\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644581006374954\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442973375182155\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439049261011405\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441508572929817\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443947960515807\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644226588951701\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644467807436098\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441347559245804\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644225199962767\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444021542511303\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441947763486573\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643956060685066\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440803584528766\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441240832957\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643795987995344\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436674118091635\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438606703544526\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643730085862182\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644002688540313\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440168348337245\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441393228682564\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441210936951576\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644344435624102\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644392848577835\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440146976389933\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441176672529443\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644005445867927\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643820856825942\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644076135998972\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440196243435\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442093047445764\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442869796366897\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644345184833185\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643773494920761\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440781433121274\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443765874981773\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644504205833587\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264424750697721\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445061158824995\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441674472028603\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644290908985309\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644149296124406\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644263318350208\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643941019903885\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445413599648604\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443754010199705\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446591173585277\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644089708172254\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644330406665906\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643852366007635\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643989437518107\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00014196400900932905\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0003402984503984914\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.001195808624266482\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.006200230316557327\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.038833746250260606\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.15852058075570613\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.24242200758526694\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.259512264693524\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26289270968542316\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26393819447466094\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2642136128149651\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643873105435934\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644460459512948\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444999770824695\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444926496362015\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644497809639081\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644080867546109\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644035690401027\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440509280224056\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644125561164506\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644159350575254\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443390089108115\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441632766652917\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644008030858109\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643925627656583\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643963967207155\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439574649212544\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440623280786285\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644098519479931\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644280453426681\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444285268141954\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644522367239152\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644087741539731\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644272234512212\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644305184724937\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644467952768082\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443379645662546\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439060764716266\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442563662563084\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644343733802138\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444222028170844\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644212361926803\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264407862190227\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441612322538877\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643879052007001\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440284886551424\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441468115018235\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440998248676983\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644400498032322\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644191833898657\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443651877169616\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438932402830634\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439635138845746\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441970667693876\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442547884894146\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644048749581872\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264406452300907\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440413080940944\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643981570442956\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439854115934097\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644569214938594\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644451839054134\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644186411910828\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445924244780833\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443670843527106\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644061442666784\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644033152002075\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436165681249096\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644071652409725\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441456288164195\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643759852229197\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643544655452991\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643745267405986\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643898933202072\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644134844226239\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440668283462915\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441979624418993\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442833098102886\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644035832635301\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643961306629834\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643918068492461\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438952242395175\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643723352166539\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644112183973936\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438343070913045\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441282038050845\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443249128594803\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442400487252454\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440326051223695\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440802485906567\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644058920527098\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643951187551188\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644334902558246\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644210773666393\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442369967269674\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442588481331625\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439312454001007\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441853998218107\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442450504677284\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441997452363425\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644433532429101\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00014414001505287357\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0003469586563660492\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00121556628441252\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.006437987309454911\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.04103987172350413\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.16335635864164288\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.24400578634757072\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26032531818254356\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2631447675856219\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26398879444917567\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2642876877408858\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643584860928398\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644165679350062\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445676225294545\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644132687596544\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439294933652974\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644232097059003\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643878919307026\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438921553997907\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443255259032944\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644554728326284\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644629681097561\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644276524230913\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440099894200825\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644017019953079\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644001495813098\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644320880657891\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264408192018026\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440966696227997\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644575723444178\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443293952292235\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644009830165983\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441847101763577\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441711981092114\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644037698088808\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442046059675073\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644248831088577\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445998900353646\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644255761698024\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264428834898928\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644019751650984\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644183257911828\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644495073151523\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441135439216784\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439067425672264\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442044962952954\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440358935611985\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440017726545545\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441338826402494\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644390856971426\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441710800386464\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445442578121775\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644515446573443\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442824905743345\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442818507084265\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644237313002924\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442186606036466\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441162534713775\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440680283940216\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437821362686714\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443755774910516\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440354286376916\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26434318490699527\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643552339900956\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643901206758186\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442357958687474\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264435229379612\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445502987369846\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445303298733575\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644398113944554\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644171591744314\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644173403310776\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643872473287871\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438654319030347\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439366575454054\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643838523112554\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644285949679058\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264393444186876\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437144737090434\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436849136720375\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643921549877562\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644251772054514\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442940452296393\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264458680894598\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644157922222754\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442896283012757\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643709342498493\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264381448924266\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643803126318405\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643743236418775\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643916160236162\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643965727549809\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440479975457465\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440604555550423\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643978203333962\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644002830422835\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441166378093406\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443646980384516\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443233623172874\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440900443100085\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444275169797127\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00014023688499806918\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0003364763833983871\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.001214689778452918\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0067074513112739854\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.044353593826598474\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.16640797460794796\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.24356159912869935\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2602858112946928\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2633313228641848\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2640334556891307\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643256686350939\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438236701729795\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644309427055064\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644415424108343\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264449482607604\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643893172912148\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644060112048067\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644246730971648\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644377569501741\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441387038420155\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644376123394716\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444696209184043\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442253758046813\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644627013405873\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264448971025379\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444017422503296\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444839253105146\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644775252551937\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444236126241344\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439907535390955\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644032834775637\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644396390422898\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442590520602755\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644006277990985\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643968786093434\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438616393449715\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643834968176279\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644182722287189\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442926396635424\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441404695389364\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644443580765863\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442464380177494\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441048808370887\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643961978319148\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644079686013735\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644389251184689\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440942067687784\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441182607620095\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440044784967887\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441735788605564\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440657171306253\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441840185466164\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444241908842214\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644008621978933\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644134466774275\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438212156780344\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643952346159195\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644161614596077\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439576490418837\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437273484399226\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439878889555696\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643801985665276\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644311357086331\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644162249037304\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444037911095086\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644522996281238\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643949987748469\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443454679403966\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441507492961414\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264406193090131\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439819536617154\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643944029780171\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440585554178814\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442291381840083\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436462524488075\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441184521253935\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644061093193801\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440141327275946\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643989397522585\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644163169063591\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446194054710487\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441776540597334\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443263635836856\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644321216034738\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644321005434529\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442502141709545\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444897718665467\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438830450298606\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439289091839774\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264423038987791\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441606891060776\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441530824764065\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643870303277069\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643953379007166\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439331252679743\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643922795660867\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442658504991984\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644355842688472\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644287964566725\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644468363708594\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644513767377281\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00014222503443718198\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00032976098412135604\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.001065482691529033\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00534093717723198\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.035831016890294345\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.1510187781983588\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.24147682340652685\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.25956848026050167\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26302214943350205\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26394921853000003\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26415819845331556\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643382524868216\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438533664966357\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644109448670396\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442780101604946\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644353434279868\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264432710449216\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644256777375492\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446046256084904\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644874870764836\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443649445868905\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438891421817706\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643841698133994\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442129622336175\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643542757052148\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436780573692725\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437796296932675\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436669743105357\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644137383447151\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264406083419437\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643802909260586\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644301587068568\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643758434922171\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643977729773275\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644235428185276\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644248420278555\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440601127819147\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643664644315568\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644125802938814\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438599420378783\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264384951674298\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442296518078673\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441246754354153\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442648183666617\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644581993723448\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644150198698532\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436983394545377\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441099846708216\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643811965789779\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644418410610022\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445031828467414\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644321053053165\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644389154340022\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442309092940647\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444782785910825\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264468583694872\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445270169863\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644096335223766\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441994106685834\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443234717913044\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444461154262305\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443528105294717\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644260567321095\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264440381848676\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644047484847064\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644031229939458\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264426904077018\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644521945389144\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446399015500116\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644491932937989\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446236353307\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264437324939092\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644741019602555\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26449059496895233\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26447078023191145\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644863284618083\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644911211908222\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644485258970185\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644569899470995\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442367196900735\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441863137784455\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644233549926435\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26436483927013055\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439973751501\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442519275779386\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438945082707643\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643990083963162\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644107014291037\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441779693258327\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644142847420671\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644079478595348\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440477697709314\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440057603397205\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442066813656556\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644365786863267\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644280503547587\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439985183820924\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443567148100494\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644452664586913\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444720377826486\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644330966661886\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00013627871288725873\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.00030939655301183476\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.0010388818795020326\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.005117993134438676\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.031566979719435166\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.140079005796336\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.23667889790614854\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.25886074293207273\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2629069219313148\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26392603097939427\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2642198895238663\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643469361828191\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442536358701846\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644294542531099\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644572315702314\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443136102644516\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644098796768211\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644190726620654\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438878810649924\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440705186647356\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643884504279545\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644146190997338\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441174383077126\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440984205549567\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444896915222665\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644621721737253\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442424816963384\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644526090192625\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644245962583921\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441218135799793\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442967601937284\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437888081527705\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442369557431433\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644121544904084\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644505401429613\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446827605801837\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264433093653889\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441475978105744\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439812255591155\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26438941631969715\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442529139309245\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644207004085183\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644101686846\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443753505619083\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644467166920898\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442670576197447\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644381436987016\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644440516628603\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441665443149814\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437669594521\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644086308006545\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643980303035959\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26440645779456406\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443214450741187\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644106598435467\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443535165665344\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644382376067369\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643814079798178\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264395438560523\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444054058251487\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26446048724783405\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644312935189304\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644036190915843\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443767271141083\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442009583866655\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441668570795196\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439014661897814\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442218681862384\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441605439006627\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264401243035279\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644026451128159\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644253117883554\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264412866921066\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644025327838916\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643624759642595\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26437576932911144\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.264390655671002\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444252737419316\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644549422683261\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26444009707842314\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644216797789056\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443969648534027\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644049719594777\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443950139949474\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644578646500007\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26445979001997794\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441391086260935\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644086441620395\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26439238524476305\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644044761036736\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26443526493089003\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26442108776995354\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644092477817141\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2643508484251217\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.26441557544991806\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644048895811439\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644234376652088\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644248443788331\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644300306749512\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644219199992195\n",
      " action: [0.09852648 0.26327372 0.        ], reward: -0.2644379847483028\n",
      "TD3 reward = -252.88595 +/- 0.17377\n"
     ]
    }
   ],
   "source": [
    "mean_rew, std_rew = evaluate_policy(tunningAgent, evalEnv)\n",
    "print(f\"TD3 reward = {mean_rew:.5f} +/- {std_rew:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e548def8-cdc5-48e2-bbbf-a48c681e3456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6125788853c3478cbffe59030b701100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", vec_env, verbose=0, \n",
    "            learning_rate =  0.99, # orginal = 0.9447561168646137\n",
    "            tensorboard_log=\"/home/rstudio/logs\")\n",
    "model.learn(\n",
    "\ttotal_timesteps=250_000, \n",
    "\tprogress_bar=True,\n",
    ")\n",
    "model.save(\"ppo_gcse\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
